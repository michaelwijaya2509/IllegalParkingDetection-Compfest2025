{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2abfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from collections import defaultdict, deque\n",
    "from math import sqrt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf16e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved URL: https://manifest.googlevideo.com/api/manifest/hls_playlist/expire/1754082386/ei/8teMaPTSBq2RssUPoM-40A4/ip/103.19.109.10/id/muijHPW82vI.3/itag/96/source/yt_live_broadcast/requiressl/yes/ratebypass/yes/live/1/sgoap/gir%3Dyes%3Bitag%3D140/sgovp/gir%3Dyes%3Bitag%3D137/rqh/1/hls_chunk_host/rr2---sn-oxujpup2xgn5q5-jb3e.googlevideo.com/xpc/EgVo2aDSNQ%3D%3D/playlist_duration/30/manifest_duration/30/bui/AY1jyLOOcrNeWajyVBpsQN4R46RyPd7YAV1qDmmdP-wfbLcB5BbX6PCYQBvxpcTCMtAaUWYWksbfxAz8/spc/l3OVKVBmqVkBy3fN_OTYz2ma/vprv/1/playlist_type/DVR/initcwndbps/1242500/met/1754060787,/mh/EU/mm/44/mn/sn-oxujpup2xgn5q5-jb3e/ms/lva/mv/m/mvi/2/pl/24/rms/lva,lva/dover/11/pacing/0/keepalive/yes/fexp/51355912/mt/1754060430/sparams/expire,ei,ip,id,itag,source,requiressl,ratebypass,live,sgoap,sgovp,rqh,xpc,playlist_duration,manifest_duration,bui,spc,vprv,playlist_type/sig/AJfQdSswRQIgYpPPOAmtBbcd5wbFR_AoBsoVrrg-hfwiKkcQkCkAI08CIQDrEW8HSrYUeAM3rUEDzAs5rqyCbZ4vsRTelYDeGVyJJQ%3D%3D/lsparams/hls_chunk_host,initcwndbps,met,mh,mm,mn,ms,mv,mvi,pl,rms/lsig/APaTxxMwRAIgEqiza-M6f0PlJIfQTii9cNp2kTXvnZEyLI4hS4z78WoCIASMyiXEspjVJbyBCPTNKwf71eWt4xJj74VIiexkG6Cz/playlist/index.m3u8\n"
     ]
    }
   ],
   "source": [
    "#buat video youtube ke m3u8\n",
    "import yt_dlp\n",
    "\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=muijHPW82vI\"\n",
    "\n",
    "ydl_opts = {\n",
    "    'quiet': True,\n",
    "    'skip_download': True,\n",
    "    'force_generic_extractor': False,\n",
    "    'format': 'best[ext=mp4]',\n",
    "    'simulate': True,\n",
    "    'forceurl': True,\n",
    "    'forcejson': True,\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(VIDEO_URL, download=False)\n",
    "    m3u8_url = info['url']\n",
    "    print(\"Resolved URL:\", m3u8_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cdc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_polygon(x, y, polygon):\n",
    "    return cv2.pointPolygonTest(np.array(polygon, np.int32), (int(x), int(y)), False) >= 0\n",
    "\n",
    "def boxes_overlap(person_box, vehicle_box):\n",
    "    px_center = (person_box[0] + person_box[2]) / 2\n",
    "    py_center = (person_box[1] + person_box[3]) / 2\n",
    "    \n",
    "    vx1, vy1, vx2, vy2 = vehicle_box\n",
    "    \n",
    "    if vx1 < px_center < vx2 and vy1 < py_center < vy2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def realtime_event_detection(stream_url, zona_json):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = YOLO('yolo11n.pt')\n",
    "    model.to(device)\n",
    "    label_map = model.names\n",
    "    tracker = DeepSort(max_age=30)\n",
    "    \n",
    "    with open(zona_json, 'r') as f:\n",
    "        red_zone_polygon = json.load(f)\n",
    "\n",
    "    cap = cv2.VideoCapture(stream_url)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video source: {stream_url}\")\n",
    "        return\n",
    "\n",
    "    vehicle_frame_buffers = defaultdict(lambda: deque(maxlen=120)) \n",
    "    vehicle_positions = {} \n",
    "    saved_events = set()\n",
    "\n",
    "    output_dir = \"event_dataset\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "\n",
    "        results = model(frame, verbose=False)[0]\n",
    "        detections = []\n",
    "        for box in results.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            if conf > 0.45: \n",
    "                cls_id = int(box.cls[0])\n",
    "                if label_map.get(cls_id) in [\"car\", \"truck\", \"bus\", \"person\"]:\n",
    "                    xyxy = box.xyxy[0].cpu().numpy()\n",
    "                    x1, y1, x2, y2 = xyxy\n",
    "                    w, h = x2 - x1, y2 - y1\n",
    "                    detections.append(([x1, y1, w, h], conf, cls_id))\n",
    "        \n",
    "        tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "        current_vehicles = {}\n",
    "        current_people = {}\n",
    "\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "\n",
    "            track_id = track.track_id\n",
    "            ltrb = track.to_ltrb()\n",
    "            cls_id = track.det_class\n",
    "            label = label_map.get(cls_id, 'unknown')\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, ltrb)\n",
    "            color = (0, 255, 0) if \"car\" in label else (255, 100, 100)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            label_text = f\"ID:{track_id}\"\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            \n",
    "\n",
    "            if label in [\"car\", \"truck\", \"bus\"]:\n",
    "                vehicle_frame_buffers[track_id].append(frame.copy())\n",
    "                cx = int((x1 + x2) / 2)\n",
    "                cy = int((y1 + y2) / 2)\n",
    "                vehicle_positions[track_id] = (cx, cy)\n",
    "                current_vehicles[track_id] = {'box': ltrb}\n",
    "            \n",
    "            elif label == \"person\":\n",
    "                current_people[track_id] = {'box': ltrb}\n",
    "\n",
    "        #deteksi overlap\n",
    "        for p_id, p_data in current_people.items():\n",
    "            for v_id, v_data in current_vehicles.items():\n",
    "                if v_id in saved_events:\n",
    "                    continue\n",
    "                \n",
    "                # Cek kalo mobil ada di zona ilegal\n",
    "                v_cx, v_cy = vehicle_positions[v_id]\n",
    "                if not point_in_polygon(v_cx, v_cy, red_zone_polygon):\n",
    "                    continue\n",
    "\n",
    "                # kalo box orang dan mobil overlap\n",
    "                if boxes_overlap(p_data['box'], v_data['box']):\n",
    "                    print(f\" Orang {p_id} overlap sama vehicle {v_id}.\")\n",
    "                    \n",
    "                    # Ambil 120 frame sebelum \n",
    "                    sequence_to_save = list(vehicle_frame_buffers[v_id])\n",
    "                    \n",
    "                    if len(sequence_to_save) > 0:\n",
    "                        seq_dir = os.path.join(output_dir, f\"event_{int(v_id):04d}\")\n",
    "                        os.makedirs(seq_dir, exist_ok=True)\n",
    "                        \n",
    "                        vx1, vy1, vx2, vy2 = map(int, v_data['box'])\n",
    "\n",
    "                        margin_w = int((vx2 - vx1) * 0.30) \n",
    "                        margin_h = int((vy2 - vy1) * 0.30)\n",
    "\n",
    "                        h_img, w_img, _ = frame.shape\n",
    "                        x1_crop = max(0, vx1 - margin_w)\n",
    "                        y1_crop = max(0, vy1 - margin_h)\n",
    "                        x2_crop = min(w_img, vx2 + margin_w)\n",
    "                        y2_crop = min(h_img, vy2 + margin_h)\n",
    "                        \n",
    "                        #simplify ke 16 frames yang merepresentasikan semua clip\n",
    "                        total_frames_in_buffer = len(sequence_to_save)\n",
    "                        target_frames = 16\n",
    "                        \n",
    "                        if total_frames_in_buffer >= target_frames:\n",
    "                            interval = total_frames_in_buffer // target_frames\n",
    "                            sampled_indices = [i * interval for i in range(target_frames)]\n",
    "                        else:\n",
    "                            sampled_indices = range(total_frames_in_buffer)\n",
    "\n",
    "                        for i, frame_index in enumerate(sampled_indices):\n",
    "                            img_frame = sequence_to_save[frame_index]\n",
    "                            \n",
    "                            crop = img_frame[y1_crop:y2_crop, x1_crop:x2_crop]\n",
    "                            if crop.shape[0] > 0 and crop.shape[1] > 0:\n",
    "                                crop_resized = cv2.resize(crop, (224, 224))\n",
    "                                cv2.imwrite(os.path.join(seq_dir, f\"frame_{i:02d}.jpg\"), crop_resized)\n",
    "                        \n",
    "                        print(f\"Saved {len(sequence_to_save)} frames to {seq_dir}\")\n",
    "                        saved_events.add(v_id)\n",
    "                    \n",
    "                    break \n",
    "            \n",
    "        cv2.polylines(frame, [np.array(red_zone_polygon, dtype=np.int32)], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "        cv2.imshow('Deteksi Event', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be702dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Orang 13 overlap sama vehicle 4.\n",
      "Saved 120 frames to event_dataset/event_0004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m data_video = \u001b[33m\"\u001b[39m\u001b[33mtest.mp4\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m      2\u001b[39m data_zona = \u001b[33m\"\u001b[39m\u001b[33mzona_vietnam2.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mrealtime_event_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_zona\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36mrealtime_event_detection\u001b[39m\u001b[34m(stream_url, zona_json)\u001b[39m\n\u001b[32m    140\u001b[39m     cv2.polylines(frame, [np.array(red_zone_polygon, dtype=np.int32)], isClosed=\u001b[38;5;28;01mTrue\u001b[39;00m, color=(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m), thickness=\u001b[32m2\u001b[39m)\n\u001b[32m    141\u001b[39m     cv2.imshow(\u001b[33m'\u001b[39m\u001b[33mDeteksi Event\u001b[39m\u001b[33m'\u001b[39m, frame)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m & \u001b[32m0xFF\u001b[39m == \u001b[38;5;28mord\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    143\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    145\u001b[39m cap.release()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data_video = \"test.mp4\" \n",
    "data_zona = \"zona_vietnam2.json\"\n",
    "realtime_event_detection(data_video, data_zona)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
