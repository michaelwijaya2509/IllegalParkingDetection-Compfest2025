{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNConfig:\n",
    "    #ini masih single frame classification, next stepnya lstm + sequential classification\n",
    "    \n",
    "    IMAGE_SIZE = (224, 224)  \n",
    "    NUM_CLASSES = 2  \n",
    "    \n",
    "\n",
    "    MODEL_NAME = \"efficientnet_b7\"\n",
    "    CNN_FEATURE_SIZE = 2560  \n",
    "    DROPOUT = 0.4\n",
    "    \n",
    "    K_FOLDS = 5\n",
    "    FINAL_TEST_SIZE = 0.15\n",
    "    BATCH_SIZE = 8  \n",
    "    EPOCHS = 30\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    PATIENCE = 10\n",
    "    MIN_DELTA = 0.001\n",
    "    \n",
    "\n",
    "    ROTATION_RANGE = 15\n",
    "    BRIGHTNESS_RANGE = 0.2\n",
    "    CONTRAST_RANGE = 0.2\n",
    "    \n",
    "    #ini gw namain foldernya event, ubah aja sesuai penamaan\n",
    "    DATA_DIR = \"event/The Dataset\"\n",
    "    MODEL_DIR = \"models/phase1_cnn\"\n",
    "    RESULTS_DIR = \"results/phase1_cnn\"\n",
    "    LOGS_DIR = \"logs\"\n",
    "    \n",
    "    MLFLOW_EXPERIMENT_NAME = \"car_exit_detection_phase1_cnn\"\n",
    "    MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"  \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.create_directories()\n",
    "        self.setup_mlflow()\n",
    "    \n",
    "    def create_directories(self):\n",
    "        directories = [\n",
    "            self.MODEL_DIR, \n",
    "            self.RESULTS_DIR, \n",
    "            self.LOGS_DIR,\n",
    "            \"mlruns\"\n",
    "        ]\n",
    "        \n",
    "        for dir_path in directories:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            logger.info(f\"Created directory: {dir_path}\")\n",
    "    \n",
    "    def setup_mlflow(self):\n",
    "        \n",
    "        mlflow.set_tracking_uri(self.MLFLOW_TRACKING_URI)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            mlflow.set_experiment(self.MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "            experiment = mlflow.get_experiment_by_name(self.MLFLOW_EXPERIMENT_NAME)\n",
    "            if experiment is None:\n",
    "                experiment_id = mlflow.create_experiment(self.MLFLOW_EXPERIMENT_NAME)\n",
    "                logger.info(f\"Created MLFlow experiment: {self.MLFLOW_EXPERIMENT_NAME}\")\n",
    "            else:\n",
    "                experiment_id = experiment.experiment_id\n",
    "                logger.info(f\"Using existing MLFlow experiment: {self.MLFLOW_EXPERIMENT_NAME}\")\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"MLFlow setup failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarExitCNNDataset(Dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    masih single frame classfication\n",
    "    \n",
    "    loads individual images from sequence folders and treats\n",
    "    each image as an independent sample for CNN training.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths: List[str], labels: List[int], transform=None):\n",
    "      \n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "        logger.info(f\"Dataset initialized with {len(image_paths)} images\")\n",
    "        logger.info(f\"Class distribution: {dict(zip(*np.unique(labels, return_counts=True)))}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image_path = self.image_paths[idx]\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error loading image {self.image_paths[idx]}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNCarExitClassifier(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, num_classes: int = 2, dropout: float = 0.4, cnn_feature_size: int = 2560):\n",
    "   \n",
    "        super(CNNCarExitClassifier, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        \n",
    "\n",
    "        self.backbone = efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        self._freeze_backbone()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cnn_feature_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.25),\n",
    "            \n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._initialize_classifier_weights()\n",
    "        \n",
    "        logger.info(f\"CNN Classifier initialized with {self._count_parameters():,} parameters\")\n",
    "    \n",
    "    def _freeze_backbone(self):\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        logger.info(\"Backbone frozen for stable training\")\n",
    "    \n",
    "    def unfreeze_backbone(self, unfreeze_layers: int = -1):\n",
    "        \n",
    "        if unfreeze_layers == -1:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "            logger.info(\"All backbone layers unfrozen for fine-tuning\")\n",
    "        else:\n",
    "            layers = list(self.backbone.features.children())\n",
    "            for layer in layers[-unfreeze_layers:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "            logger.info(f\"Last {unfreeze_layers} backbone layers unfrozen for fine-tuning\")\n",
    "    \n",
    "    def _initialize_classifier_weights(self):\n",
    "\n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def _count_parameters(self) -> int:\n",
    "\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    \n",
    "    def forward(self, x):\n",
    "      \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTrainer:\n",
    "\n",
    "    def __init__(self, config: CNNConfig, device: torch.device):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.client = MlflowClient()\n",
    "        \n",
    "        logger.info(f\"Trainer initialized on device: {device}\")\n",
    "    \n",
    "    def create_transforms(self) -> Tuple[transforms.Compose, transforms.Compose]:\n",
    "    \n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(self.config.IMAGE_SIZE, scale=(0.85, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.3),\n",
    "            transforms.RandomRotation(degrees=self.config.ROTATION_RANGE),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=self.config.BRIGHTNESS_RANGE,\n",
    "                contrast=self.config.CONTRAST_RANGE,\n",
    "                saturation=0.1,\n",
    "                hue=0.05\n",
    "            ),\n",
    "            transforms.RandomApply([\n",
    "                transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))\n",
    "            ], p=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n",
    "        ])\n",
    "        \n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop(self.config.IMAGE_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        return train_transform, val_transform\n",
    "    \n",
    "    def train_fold(self, model: nn.Module, train_loader: DataLoader, \n",
    "                   val_loader: DataLoader, fold_num: int) -> Tuple[nn.Module, Dict, float]:\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr=self.config.LEARNING_RATE,\n",
    "            weight_decay=self.config.WEIGHT_DECAY\n",
    "        )\n",
    "        \n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.config.LEARNING_RATE * 3,\n",
    "            epochs=self.config.EPOCHS,\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            pct_start=0.3\n",
    "        )\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': []\n",
    "        }\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        logger.info(f\"Training Fold {fold_num} - {len(train_loader.dataset)} samples\")\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            pbar = tqdm(train_loader, desc=f'Fold {fold_num} Epoch {epoch+1}', leave=False)\n",
    "            for images, labels in pbar:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100.*train_correct/train_total:.1f}%'\n",
    "                })\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_train_loss = train_loss / len(train_loader)\n",
    "            epoch_train_acc = train_correct / train_total\n",
    "            epoch_val_loss = val_loss / len(val_loader)\n",
    "            epoch_val_acc = val_correct / val_total\n",
    "            \n",
    "            history['train_loss'].append(epoch_train_loss)\n",
    "            history['train_acc'].append(epoch_train_acc)\n",
    "            history['val_loss'].append(epoch_val_loss)\n",
    "            history['val_acc'].append(epoch_val_acc)\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                f'fold_{fold_num}_train_loss': epoch_train_loss,\n",
    "                f'fold_{fold_num}_train_acc': epoch_train_acc,\n",
    "                f'fold_{fold_num}_val_loss': epoch_val_loss,\n",
    "                f'fold_{fold_num}_val_acc': epoch_val_acc\n",
    "            }, step=epoch)\n",
    "            \n",
    "            logger.info(f\"Epoch {epoch+1:2d}/{self.config.EPOCHS} \"\n",
    "                       f\"Train: {epoch_train_loss:.4f}/{epoch_train_acc:.4f} \"\n",
    "                       f\"Val: {epoch_val_loss:.4f}/{epoch_val_acc:.4f}\")\n",
    "            \n",
    "\n",
    "            if epoch_val_acc > best_val_acc + self.config.MIN_DELTA:\n",
    "                best_val_acc = epoch_val_acc\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                logger.info(f\"New best model - Val Acc: {epoch_val_acc:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "    \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                logger.info(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if best_model_state:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        return model, history, best_val_acc\n",
    "    \n",
    "    def cross_validate(self, dataset: CarExitCNNDataset) -> Tuple[List[Dict], Dict, nn.Module]:\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"cnn_cv_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "            \n",
    "            mlflow.log_params({\n",
    "                'model_type': 'CNN_EfficientNet_B7',\n",
    "                'k_folds': self.config.K_FOLDS,\n",
    "                'batch_size': self.config.BATCH_SIZE,\n",
    "                'epochs': self.config.EPOCHS,\n",
    "                'learning_rate': self.config.LEARNING_RATE,\n",
    "                'dropout': self.config.DROPOUT,\n",
    "                'image_size': str(self.config.IMAGE_SIZE)\n",
    "            })\n",
    "            \n",
    "            labels = np.array(dataset.labels)\n",
    "            skf = StratifiedKFold(n_splits=self.config.K_FOLDS, shuffle=True, random_state=42)\n",
    "            \n",
    "            fold_results = []\n",
    "            all_models = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(skf.split(range(len(dataset)), labels)):\n",
    "                logger.info(f\"\\nFOLD {fold + 1}/{self.config.K_FOLDS}\")\n",
    "                \n",
    "                train_sampler = SubsetRandomSampler(train_idx)\n",
    "                val_sampler = SubsetRandomSampler(val_idx)\n",
    "            \n",
    "                train_loader = DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=self.config.BATCH_SIZE,\n",
    "                    sampler=train_sampler,\n",
    "                    num_workers=0,\n",
    "                    pin_memory=True\n",
    "                )\n",
    "                \n",
    "                val_loader = DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=self.config.BATCH_SIZE,\n",
    "                    sampler=val_sampler,\n",
    "                    num_workers=0,\n",
    "                    pin_memory=True\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"Training samples: {len(train_idx)}, Validation samples: {len(val_idx)}\")\n",
    "                \n",
    "                model = CNNCarExitClassifier(\n",
    "                    num_classes=self.config.NUM_CLASSES,\n",
    "                    dropout=self.config.DROPOUT,\n",
    "                    cnn_feature_size=self.config.CNN_FEATURE_SIZE\n",
    "                ).to(self.device)\n",
    "                \n",
    "                model, history, best_val_acc = self.train_fold(model, train_loader, val_loader, fold + 1)\n",
    "                \n",
    "                fold_result = {\n",
    "                    'fold': fold + 1,\n",
    "                    'best_val_acc': best_val_acc,\n",
    "                    'final_train_acc': history['train_acc'][-1],\n",
    "                    'final_val_acc': history['val_acc'][-1],\n",
    "                    'history': history\n",
    "                }\n",
    "                \n",
    "                fold_results.append(fold_result)\n",
    "                all_models.append(model)\n",
    "                \n",
    "                fold_model_path = os.path.join(self.config.MODEL_DIR, f'fold_{fold+1}_model.pth')\n",
    "                torch.save({\n",
    "                    'fold': fold + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'best_val_acc': best_val_acc,\n",
    "                    'fold_result': fold_result\n",
    "                }, fold_model_path)\n",
    "                \n",
    "                mlflow.log_artifact(fold_model_path, f\"models/fold_{fold+1}\")\n",
    "                \n",
    "                logger.info(f\"✅ Fold {fold+1} completed - Best Val Acc: {best_val_acc:.4f}\")\n",
    "            \n",
    "            cv_stats = self._calculate_cv_statistics(fold_results)\n",
    "            \n",
    "            # Log CV statistics\n",
    "            mlflow.log_metrics({\n",
    "                'cv_mean_val_acc': cv_stats['mean_val_acc'],\n",
    "                'cv_std_val_acc': cv_stats['std_val_acc'],\n",
    "                'cv_mean_train_acc': cv_stats['mean_train_acc'],\n",
    "                'cv_std_train_acc': cv_stats['std_train_acc']\n",
    "            })\n",
    "            \n",
    "            # save best model\n",
    "            best_fold_idx = np.argmax([r['best_val_acc'] for r in fold_results])\n",
    "            best_model = all_models[best_fold_idx]\n",
    "            \n",
    "            best_model_path = os.path.join(self.config.MODEL_DIR, 'best_cnn_model.pth')\n",
    "            torch.save({\n",
    "                'model_state_dict': best_model.state_dict(),\n",
    "                'cv_stats': cv_stats,\n",
    "                'best_fold': best_fold_idx + 1,\n",
    "                'config': self.config.__dict__\n",
    "            }, best_model_path)\n",
    "            \n",
    "            # Log best model\n",
    "            mlflow.pytorch.log_model(best_model, \"best_model\")\n",
    "            mlflow.log_artifact(best_model_path, \"models\")\n",
    "            \n",
    "            return fold_results, cv_stats, best_model\n",
    "\n",
    "    def _calculate_cv_statistics(self, fold_results: List[Dict]) -> Dict:\n",
    "\n",
    "        val_accs = [r['best_val_acc'] for r in fold_results]\n",
    "        train_accs = [r['final_train_acc'] for r in fold_results]\n",
    "        \n",
    "        cv_stats = {\n",
    "            'mean_val_acc': np.mean(val_accs),\n",
    "            'std_val_acc': np.std(val_accs),\n",
    "            'mean_train_acc': np.mean(train_accs),\n",
    "            'std_train_acc': np.std(train_accs),\n",
    "            'fold_results': fold_results\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"\\nCROSS-VALIDATION RESULTS\")\n",
    "        logger.info(f\"Mean Validation Accuracy: {cv_stats['mean_val_acc']:.4f} ± {cv_stats['std_val_acc']:.4f}\")\n",
    "        logger.info(f\"Mean Training Accuracy: {cv_stats['mean_train_acc']:.4f} ± {cv_stats['std_train_acc']:.4f}\")\n",
    "        \n",
    "        return cv_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_data(data_dir: str) -> Tuple[List[str], List[int]]:\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_label in [0, 1]:\n",
    "        class_dir = os.path.join(data_dir, str(class_label))\n",
    "        \n",
    "        if not os.path.exists(class_dir):\n",
    "            logger.warning(f\"Class directory {class_dir} not found\")\n",
    "            continue\n",
    "        \n",
    "        sequence_folders = [d for d in os.listdir(class_dir) \n",
    "                           if os.path.isdir(os.path.join(class_dir, d))]\n",
    "        \n",
    "        for seq_folder in sequence_folders:\n",
    "            seq_path = os.path.join(class_dir, seq_folder)\n",
    "            \n",
    "            extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "            sequence_images = []\n",
    "            for ext in extensions:\n",
    "                sequence_images.extend(glob.glob(os.path.join(seq_path, ext)))\n",
    "            \n",
    "            for img_path in sequence_images:\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(class_label)\n",
    "    \n",
    "    logger.info(f\"Dataset loaded:\")\n",
    "    logger.info(f\"Total images: {len(image_paths)}\")\n",
    "    logger.info(f\"Class 0 (Normal): {labels.count(0)} images\")\n",
    "    logger.info(f\"Class 1 (Person Exiting): {labels.count(1)} images\")\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        raise ValueError(\"No images found.\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(cv_stats: Dict, config: CNNConfig):\n",
    "\n",
    "    fold_results = cv_stats['fold_results']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('CNN Phase 1 - Cross Validation Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    folds = [r['fold'] for r in fold_results]\n",
    "    train_accs = [r['final_train_acc'] for r in fold_results]\n",
    "    val_accs = [r['best_val_acc'] for r in fold_results]\n",
    "    \n",
    "    x = np.arange(len(folds))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0, 0].bar(x - width/2, train_accs, width, label='Training', alpha=0.8, color='skyblue')\n",
    "    axes[0, 0].bar(x + width/2, val_accs, width, label='Validation', alpha=0.8, color='lightcoral')\n",
    "    axes[0, 0].set_title('Accuracy by Fold')\n",
    "    axes[0, 0].set_xlabel('Fold')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].set_xticks(x)\n",
    "    axes[0, 0].set_xticklabels(folds)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    best_fold_idx = np.argmax(val_accs)\n",
    "    best_history = fold_results[best_fold_idx]['history']\n",
    "    \n",
    "    epochs = range(1, len(best_history['train_acc']) + 1)\n",
    "    axes[0, 1].plot(epochs, best_history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, best_history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_title(f'Best Fold ({best_fold_idx+1}) - Training History')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    mean_val = cv_stats['mean_val_acc']\n",
    "    std_val = cv_stats['std_val_acc']\n",
    "    \n",
    "    axes[1, 0].errorbar([1], [mean_val], yerr=[std_val], \n",
    "                       fmt='o', markersize=15, capsize=10, capthick=3, color='green')\n",
    "    axes[1, 0].set_xlim([0.5, 1.5])\n",
    "    axes[1, 0].set_ylim([max(0, mean_val - 2*std_val), min(1, mean_val + 2*std_val)])\n",
    "    axes[1, 0].set_title(f'CV Mean ± Std\\n{mean_val:.4f} ± {std_val:.4f}')\n",
    "    axes[1, 0].set_xticks([])\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].plot(epochs, best_history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    axes[1, 1].plot(epochs, best_history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    axes[1, 1].set_title(f'Best Fold ({best_fold_idx+1}) - Loss History')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = os.path.join(config.RESULTS_DIR, 'cv_results_visualization.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    mlflow.log_artifact(plot_path)\n",
    "    return plot_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model_path: str, image_path: str, config: CNNConfig, \n",
    "                        return_probabilities: bool = True) -> Dict[str, Any]:\n",
    "    \n",
    "    try:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        model = CNNCarExitClassifier(\n",
    "            num_classes=config.NUM_CLASSES,\n",
    "            dropout=config.DROPOUT\n",
    "        )\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        _, val_transform = CNNTrainer(config, device).create_transforms()\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = val_transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            prediction = predicted.cpu().item()\n",
    "            confidence = probabilities[0, prediction].cpu().item()\n",
    "            \n",
    "            result = {\n",
    "                'prediction': prediction,\n",
    "                'class_name': 'person_exiting' if prediction == 1 else 'normal_parking',\n",
    "                'confidence': confidence,\n",
    "                'image_path': image_path\n",
    "            }\n",
    "            \n",
    "            if return_probabilities:\n",
    "                result['probabilities'] = {\n",
    "                    'normal_parking': probabilities[0, 0].cpu().item(),\n",
    "                    'person_exiting': probabilities[0, 1].cpu().item()\n",
    "                }\n",
    "            \n",
    "            logger.info(f\"Prediction: {result['class_name']} (confidence: {confidence:.4f})\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prediction failed: {e}\")\n",
    "        return {'error': f'Prediction failed: {str(e)}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_set(model: nn.Module, test_loader: DataLoader, device: torch.device, \n",
    "                     config: CNNConfig) -> Dict[str, float]:\n",
    " \n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating test set\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "  \n",
    "    test_accuracy = test_correct / test_total\n",
    "    test_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    test_precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    test_recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "\n",
    "    test_f1_per_class = f1_score(all_labels, all_predictions, average=None)\n",
    "    test_precision_per_class = precision_score(all_labels, all_predictions, average=None)\n",
    "    test_recall_per_class = recall_score(all_labels, all_predictions, average=None)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': test_accuracy,\n",
    "        'f1_weighted': test_f1,\n",
    "        'precision_weighted': test_precision,\n",
    "        'recall_weighted': test_recall,\n",
    "        'f1_normal': test_f1_per_class[0],\n",
    "        'f1_person_exiting': test_f1_per_class[1],\n",
    "        'precision_normal': test_precision_per_class[0],\n",
    "        'precision_person_exiting': test_precision_per_class[1],\n",
    "        'recall_normal': test_recall_per_class[0],\n",
    "        'recall_person_exiting': test_recall_per_class[1],\n",
    "        'test_samples': test_total\n",
    "    }\n",
    "    \n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=['Normal Parking', 'Person Exiting'],\n",
    "               yticklabels=['Normal Parking', 'Person Exiting'])\n",
    "    plt.title('Test Set Confusion Matrix', fontweight='bold', fontsize=14)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "  \n",
    "    cm_path = os.path.join(config.RESULTS_DIR, 'test_confusion_matrix.png')\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    \n",
    "\n",
    "    class_names = ['Normal Parking', 'Person Exiting']\n",
    "    report = classification_report(all_labels, all_predictions, target_names=class_names)\n",
    "    logger.info(f\"\\nTEST SET EVALUATION:\")\n",
    "    logger.info(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    logger.info(f\"Test F1-Score (weighted): {test_f1:.4f}\")\n",
    "    logger.info(f\"Test Precision (weighted): {test_precision:.4f}\")\n",
    "    logger.info(f\"Test Recall (weighted): {test_recall:.4f}\")\n",
    "    logger.info(f\"\\nDetailed Classification Report:\\n{report}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    try:\n",
    " \n",
    "        config = CNNConfig()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Device: {device}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "        if os.path.exists(\"dataset_parking.zip\") and not os.path.exists(config.DATA_DIR):\n",
    "            os.makedirs(\"event\", exist_ok=True)\n",
    "            with zipfile.ZipFile(\"dataset_parking.zip\", 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"event\")\n",
    "        \n",
    "        # Load data\n",
    "        image_paths, labels = load_image_data(config.DATA_DIR)\n",
    "        \n",
    "        # Check class balance\n",
    "        class_counts = {0: labels.count(0), 1: labels.count(1)}\n",
    "        logger.info(f\"Class distribution: {class_counts}\")\n",
    "        \n",
    "        if config.FINAL_TEST_SIZE > 0:\n",
    "            train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "                image_paths, labels,\n",
    "                test_size=config.FINAL_TEST_SIZE,\n",
    "                stratify=labels,\n",
    "                random_state=42\n",
    "            )\n",
    "            logger.info(f\"Data split:\")\n",
    "            logger.info(f\"Cross-validation set: {len(train_val_paths)} images\")\n",
    "            logger.info(f\"Final test set: {len(test_paths)} images\")\n",
    "        else:\n",
    "            train_val_paths, train_val_labels = image_paths, labels\n",
    "            test_paths, test_labels = [], []\n",
    "            logger.info(f\"Using all {len(image_paths)} images for cross-validation\")\n",
    "        \n",
    "        # Create datasets\n",
    "        trainer = CNNTrainer(config, device)\n",
    "        train_transform, val_transform = trainer.create_transforms()\n",
    "        \n",
    "        # Cross-validation dataset \n",
    "        cv_dataset = CarExitCNNDataset(train_val_paths, train_val_labels, transform=train_transform)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        fold_results, cv_stats, best_model = trainer.cross_validate(cv_dataset)\n",
    "        \n",
    "        # Visualize results\n",
    "        visualize_results(cv_stats, config)\n",
    "        \n",
    "        # Evaluate on test set if available\n",
    "        test_metrics = None\n",
    "        if test_paths:\n",
    "            test_dataset = CarExitCNNDataset(test_paths, test_labels, transform=val_transform)\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=config.BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                pin_memory=True\n",
    "            )\n",
    "            \n",
    "            test_metrics = evaluate_test_set(best_model, test_loader, device, config)\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                'test_accuracy': test_metrics['accuracy'],\n",
    "                'test_f1_weighted': test_metrics['f1_weighted'],\n",
    "                'test_precision_weighted': test_metrics['precision_weighted'],\n",
    "                'test_recall_weighted': test_metrics['recall_weighted']\n",
    "            })\n",
    "        \n",
    "        results_summary = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'phase': 'Phase 1 - CNN Implementation',\n",
    "            'model_architecture': 'EfficientNet-B7 + Custom Classifier',\n",
    "            'config': {\n",
    "                'k_folds': config.K_FOLDS,\n",
    "                'model_name': config.MODEL_NAME,\n",
    "                'batch_size': config.BATCH_SIZE,\n",
    "                'epochs': config.EPOCHS,\n",
    "                'learning_rate': config.LEARNING_RATE,\n",
    "                'dropout': config.DROPOUT,\n",
    "                'image_size': config.IMAGE_SIZE\n",
    "            },\n",
    "            'data_info': {\n",
    "                'total_images': len(image_paths),\n",
    "                'train_val_images': len(train_val_paths),\n",
    "                'test_images': len(test_paths) if test_paths else 0,\n",
    "                'class_distribution': class_counts\n",
    "            },\n",
    "            'cross_validation': {\n",
    "                'mean_val_accuracy': cv_stats['mean_val_acc'],\n",
    "                'std_val_accuracy': cv_stats['std_val_acc'],\n",
    "                'mean_train_accuracy': cv_stats['mean_train_acc'],\n",
    "                'std_train_accuracy': cv_stats['std_train_acc'],\n",
    "                'fold_results': [\n",
    "                    {\n",
    "                        'fold': r['fold'],\n",
    "                        'best_val_acc': r['best_val_acc'],\n",
    "                        'final_train_acc': r['final_train_acc']\n",
    "                    } for r in fold_results\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if test_metrics:\n",
    "            results_summary['final_test'] = test_metrics\n",
    "        \n",
    "        results_path = os.path.join(config.RESULTS_DIR, 'phase1_cnn_results.json')\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "        \n",
    "        mlflow.log_artifact(results_path)\n",
    "        \n",
    "        logger.info(f\"Cross-Validation Accuracy: {cv_stats['mean_val_acc']:.4f} ± {cv_stats['std_val_acc']:.4f}\")\n",
    "        \n",
    "        if test_metrics:\n",
    "            logger.info(f\"Final Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        logger.info(f\"\\nSAVED FILES:\")\n",
    "        logger.info(f\"   Best model: {config.MODEL_DIR}/best_cnn_model.pth\")\n",
    "        logger.info(f\"   Individual folds: {config.MODEL_DIR}/fold_*_model.pth\")\n",
    "        logger.info(f\"   Results summary: {results_path}\")\n",
    "        logger.info(f\"   Visualizations: {config.RESULTS_DIR}/\")\n",
    "        logger.info(f\"   MLFlow tracking: {config.MLFLOW_TRACKING_URI}\")\n",
    "        \n",
    "        return best_model, cv_stats, results_summary, test_metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training pipeline failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction_test():\n",
    " \n",
    "    config = CNNConfig()\n",
    "\n",
    "    try:\n",
    "        # Single image prediction \n",
    "        # next-step mulai sequential \n",
    "        result = predict_single_image(\n",
    "            model_path=os.path.join(config.MODEL_DIR, 'best_cnn_model.pth'),\n",
    "            image_path='frame_015.jpg',\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        if 'error' not in result:\n",
    "            print(f\"Prediction: {result['class_name']}\")\n",
    "            print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "            if 'probabilities' in result:\n",
    "                for class_name, prob in result['probabilities'].items():\n",
    "                    print(f\"  {class_name}: {prob:.4f}\")\n",
    "        else:\n",
    "            print(f\"Error: {result['error']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Prediction example failed: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'CarExitCNNDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "ERROR [__main__] Training pipeline failed: DataLoader worker (pid(s) 57705) exited unexpectedly\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 57702) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1285, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 1128, in wait\n",
      "    with _WaitSelector() as selector:\n",
      "         ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py\", line 202, in __exit__\n",
      "    def __exit__(self, *args):\n",
      "    \n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 57705) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/q6/7qx7_1k91_n1fwg23wdq6jw00000gn/T/ipykernel_48481/2051523238.py\", line 47, in main\n",
      "    fold_results, cv_stats, best_model = trainer.cross_validate(cv_dataset)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/q6/7qx7_1k91_n1fwg23wdq6jw00000gn/T/ipykernel_48481/1767792460.py\", line 212, in cross_validate\n",
      "    model, history, best_val_acc = self.train_fold(model, train_loader, val_loader, fold + 1)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/q6/7qx7_1k91_n1fwg23wdq6jw00000gn/T/ipykernel_48481/1767792460.py\", line 83, in train_fold\n",
      "    for images, labels in pbar:\n",
      "                          ^^^^\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 734, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1492, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1454, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vincentiusjacob/Documents/horus/IllegalParkingDetection-Compfest2025/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1298, in _try_get_data\n",
      "    raise RuntimeError(\n",
      "RuntimeError: DataLoader worker (pid(s) 57705) exited unexpectedly\n",
      "ERROR [__main__] \n",
      "Phase 1 CNN implementation failed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model, cv_stats, results, test_metrics = main()\n",
    "    \n",
    "    if model is not None:\n",
    "        run_prediction_test()\n",
    "\n",
    "    else:\n",
    "        logger.error(\"\\nPhase 1 CNN implementation failed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
