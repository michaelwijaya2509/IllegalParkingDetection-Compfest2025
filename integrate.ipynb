{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b93cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 3 cars, 3 motorcycles, 20.0ms\n",
      "Speed: 2.4ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import library\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from math import sqrt\n",
    "\n",
    "# Fix OpenMP crash\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Cell 2: Polygon helper\n",
    "def point_in_polygon(x, y, polygon):\n",
    "    return cv2.pointPolygonTest(np.array(polygon, np.int32), (int(x), int(y)), False) >= 0\n",
    "\n",
    "# Cell 3: Main detection with red zone\n",
    "def realtime_detection_with_redzone(stream_url, zona_json):\n",
    "    colors = {\n",
    "        \"car\": (255, 0, 0),\n",
    "        \"truck\": (255, 0, 0),\n",
    "        \"bus\": (255, 0, 0),\n",
    "        \"motorcycle\": (0, 255, 0),\n",
    "        \"bicycle\": (0, 255, 0),\n",
    "        \"person\": (0, 0, 255),\n",
    "    }\n",
    "    duration = {}\n",
    "    updated_position = {}\n",
    "\n",
    "    with open(zona_json, 'r') as f:\n",
    "        red_zone_polygon = json.load(f)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = YOLO('yolo11n.pt')\n",
    "    model.to(device)\n",
    "    label_map = model.names\n",
    "\n",
    "    tracker = DeepSort(max_age=30)\n",
    "\n",
    "    cap = cv2.VideoCapture(stream_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame_counter = 0\n",
    "        if not ret or frame is None:\n",
    "            print(\"Stream ended or invalid frame.\")\n",
    "            break\n",
    "\n",
    "        results = model(frame)[0]\n",
    "        detections = []\n",
    "\n",
    "        for box in results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            xyxy = box.xyxy[0].cpu().numpy()\n",
    "            x1, y1, x2, y2 = xyxy\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            x_center, y_center = x1, y1\n",
    "\n",
    "            detections.append(([x_center, y_center, w, h], conf, cls_id))\n",
    "\n",
    "        try:\n",
    "            tracks = tracker.update_tracks(detections, frame=frame)\n",
    "        except Exception as e:\n",
    "            print(\"Tracking error:\", e)\n",
    "            continue\n",
    "\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "\n",
    "            track_id = track.track_id\n",
    "            ltrb = track.to_ltrb()\n",
    "            x1, y1, x2, y2 = map(int, ltrb)\n",
    "\n",
    "            cls_id = track.det_class\n",
    "            cls_conf = track.det_conf\n",
    "            label = label_map.get(cls_id, 'unknown')\n",
    "            if cls_conf is None or label not in colors:\n",
    "                continue\n",
    "\n",
    "            cx = int((x1 + x2) / 2) # center x\n",
    "            cy = int((y1 + y2) / 2) # center y\n",
    "\n",
    "            in_red_zone = point_in_polygon(cx, cy, red_zone_polygon)\n",
    "\n",
    "            label_text = f\"{label} {track_id} {cls_conf:.2f}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), colors[label], 2)\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[label], 2)\n",
    "            cv2.circle(frame, (cx, cy), 5, colors[label], -1)\n",
    "\n",
    "            if in_red_zone:\n",
    "                if track_id not in duration:\n",
    "                    duration[track_id] = 0\n",
    "                    if track_id not in updated_position:\n",
    "                        updated_position[track_id] = (cx, cy)\n",
    "                else:\n",
    "                    # check if the vehicle is static or not (use euclidean distance)\n",
    "                    if frame_counter % 30 == 0:\n",
    "                        if sqrt((cx - updated_position[track_id][0]) ** 2 + (cy - updated_position[track_id][1]) ** 2) < 10:\n",
    "                            duration[track_id] += 1\n",
    "                        else:\n",
    "                            duration[track_id] = 0\n",
    "                        updated_position[track_id] = (cx, cy)\n",
    "                cv2.putText(frame, f\"Time {duration[track_id] // 10}s\", (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                        \n",
    "        cv2.polylines(frame, [np.array(red_zone_polygon, dtype=np.int32)], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "        cv2.imshow(f'Deteksi CCTV Real-time - ParkLens AI - {device.upper()}', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "data_video = r\"video/vietnam2.mp4\"\n",
    "data_zona = \"zona_vietnam2.json\"\n",
    "realtime_detection_with_redzone(data_video, data_zona)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
